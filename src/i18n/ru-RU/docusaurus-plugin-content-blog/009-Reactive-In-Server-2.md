---
date: 2020-06-28
title: Говоря о применении реактивного программирования на стороне службы, оптимизации операций с базами данных и ускорения Upsert
---

Реактивное программирование широко используется в клиентских программированиях, в то время как в настоящее время приложения на стороне службы упоминаются относительно реже.В этой статье показано, как улучшить производительность операций с базой данных при применении ответа в программировании на стороне службы.

<!-- more -->

<!-- md Header-Newbe-Claptrap.md -->

## Начало является заключением

После следующей статьи["О применении реактивного программирования на стороне службы, оптимизации операций с базой данных, от 20 секунд до 0,5 секунды"](008-Reactive-In-Server-1), на этот раз мы приносим тематическое описание оптимизации upsert с помощью реактивного программирования.Рекомендуется, чтобы читатели могли прочитать предыдущий, чтобы было легче понять, как описано в этой статье.

Кроме того, с помощью идеи пакетной работы отдельные операции upsert объединяются в пакетном режиме.Достигнута цель сокращения потребления ссылок на базы данных, что значительно повышает производительность.

## Бизнес-сценарий

在最近的一篇文章[《十万同时在线用户，需要多少内存？——Newbe.Claptrap 框架水平扩展实验》](003-How-Many-RAMs-In-Used-While-There-Are-One-Hundred-Thousand-Users-Online)中。Мы стремимся быстро проверить правильность JWT, активив несколько Claptrap, которые находятся в памяти.

Но тогда не была решена техническая проблема：

Платформа Newbe.Claptrap разработала функцию：Когда Claptrap Deactive, вы можете сохранить моментальный снимок в базе данных немедленно.Таким образом при попытке закрыть узел из кластера, если на узле существует большое количество Claptrap, создается большое количество операций upsert базы данных.Мгновенное потребление базы данных приводит к частичной ошибке и сбою сохранения.

## Немного кода

С помощью предыдущих`IBatchOperator`, то оставить очень мало кода для этой статьи.

Во-первых, напишите repository, который поддерживает операции, используя IBatchOperator в следующей статье, как показано в следующем：

```cs
public class BatchUpsert : IUpsertRepository
{
    private readonly IDatabase _database;
    private readonly IBatchOperator<(int, int), int> _batchOperator;

    public BatchUpsert(IDatabase database)
    {
        _database = database;
        var options = new BatchOperatorOptions<(int, int), int>
        {
            BufferCount = 100,
            BufferTime = TimeSpan.FromMilliseconds(50),
            DoManyFunc = DoManyFunc
        };
        _batchOperator = new BatchOperator<(int, int), int>(options);
    }

    private Task<int> DoManyFunc(IEnumerable<(int, int)> arg)
    {
        return _database. UpsertMany(arg. ToDictionary(x => x.Item1, x => x.Item2));
    }

    public Task UpsertAsync(int key, int value)
    {
        return _batchOperator.CreateTask((key, value));
    }
}
```

Затем эта оптимизация может быть выполнена хорошо, просто реализуя метод UpsertMany для соответствующей базы данных.

## Операции с различными базами данных

В сочетании с Newbe.Claptrap в настоящее время является фактическим проектом.В настоящее время поддерживаемыми базами данных является SQLite, PostgreSQL, MySql и MongoDB.Ниже описаны массовые операции Upsert для различных типов баз данных.

Поскольку требования Upsert в проекте Newbe.Claptrap основаны на первичном ключе в качестве контрастного ключа, это также обсуждается только ниже.

### SQLite

Согласно официальной документации, `insert OR REPLACE INTO позволяет` данных при конфликте первичного ключа.

Конкретный формат инструкции, как показано ниже：

```SQL
INSERT OR REPLACE INTO TestTable (id, value)
VALUES
(@id0,@value0),
...
(@idn,@valuen);
```

Поэтому просто сшивайте операторы и вызовы параметров напрямую.Обратите внимание, что входящий параметр SQLite по умолчанию составляет 999, поэтому сшитые переменные не должны превышать это число.

> [Официальная документация：INSERT](https://www.sqlite.org/lang_insert.html)

### PostgreSQL

众所周知，PostgreSQL 在进行批量写入时，可以使用高效的 COPY 语句来完成数据的高速导入，这远远快于 INSERT 语句。但可惜的是 COPY 并不能支持 ON CONFLICT DO UPDATE 子句。因此，无法使用 COPY 来完成 upsert 需求。

因此，我们还是回归使用 INSERT 配合 ON CONFLICT DO UPDATE 子句，以及 unnest 函数来完成批量 upsert 的需求。

Конкретный формат инструкции, как показано ниже：

```SQL
INSERT INTO TestTable (id, value)
VALUES (unnest(@ids), unnest(@values))
ON CONFLICT ON CONSTRAINT TestTable_pkey
DO UPDATE SET value=excluded.value;
```

Ids и values являются двумя однодлинными объектами массива, и функция unnest преобразует объект массива в форму данных строки.

Обратите внимание, что может возникнуть ошибка ON CONFLICT DO UPDATE command cannot affect row a second time.

Таким образом, если вы попытаетесь использовать приведенный выше сценарий, вам нужно будет повторить его в программе перед входящим в базу данных.Кроме того, как правило, один повтор в программе уменьшает данные, входящие в базу данных, что само по себе имеет смысл.

> [официальный документ：функция unnest](https://www.postgresql.org/docs/9.2/functions-array.html) > [официальный документ：оператор Insert](https://www.postgresql.org/docs/9.5/sql-insert.html)

### MySql

MySql, как и SQLite, поддерживает синтаксис replace`replace` системы.Конкретные заявления приведены ниже：

```sql
REPLACE INTO TestTable (id, value)
VALUES
(@id0,@value0),
...
(@idn,@valuen);
```

> [Официальная документация：replace](https://dev.mysql.com/doc/refman/8.0/en/replace.html)

### MongoDB

MongoDB поддерживает режим массовой передачи bulkWrite, а также синтаксис upsert replace.Таким образом, операция очень проста.

Итак, вот как это сделать на языке C：

```cs
private async Task SaveManyCoreMany(
    IDbFactory dbFactory,
    IEnumerable<StateEntity> entities)
{
    var array = entities as StateEntity[] ?? entities. ToArray();
    var items = array
        . Select(x => new MongoStateEntity
        {
            claptrap_id = x.ClaptrapId,
            claptrap_type_code = x.ClaptrapTypeCode,
            version = x.Version,
            state_data = x.StateData,
            updated_time = x.UpdatedTime,
        })
        . ToArray();

    var client = dbFactory.GetConnection(_connectionName);
    var db = client. GetDatabase(_databaseName);
    var collection = db. GetCollection<MongoStateEntity>(_stateCollectionName);

    var upsertModels = items. Select(x =>
    {
        var filter = new ExpressionFilterDefinition<MongoStateEntity>(entity =>
            entity.claptrap_id == x.claptrap_id && entity.claptrap_type_code == x.claptrap_type_code);
        return new ReplaceOneModel<MongoStateEntity>(filter, x)
        {
            IsUpsert = true
        };
    });
    await collection. BulkWriteAsync(upsertModels);
}
```

Это код, приведенный в бизнес-сценарии проекта Newbe.Claptrap, который читатель может изменить в соответствии со своими потребностями.

> [Официальная：db.collection.bulkWrite()](https://docs.mongodb.com/manual/reference/method/db.collection.bulkWrite/#db.collection.bulkWrite)

### Универсальное решение

Суть оптимизации заключается в сокращении использования ссылок на базы данных и сделать как можно больше в рамках одной ссылки.Таким образом, если определенная база данных не поддерживает вышеупомянутую базу данных, аналогичную операции.Таким образом, по-прежнему существует универсальное решение：

1. Записывайте данные во временную таблицу как можно быстрее
2. Обновляет целевую таблицу способом, с помощью которых данные временной таблицы были подключены к update таблицы
3. Удалите временную таблицу

> [UPDATE with a join](http://www.sql-workbench.eu/dbms_comparison.html)

## Тестирование производительности

На примере SQLite попробуйте выполнить 2 upsert для 12 345 данных.

Одной одной полосы：1 минуту 6 секунд

Пакетная обработка：2,9 секунды

[Тестовый код можно найти по этой ссылке.](https://github.com/newbe36524/Newbe.Demo/blob/master/src/BlogDemos/Newbe.Rx/Newbe.RxWorld/Newbe.RxWorld/UpsertTest.cs)

Пример не содержит примеров MySql, PostgreSQL и MongoDB, так как без оптимизации одно и то же в основном взрывается без улучшения пула подключений.Результатом всех оптимизаций является непосредственное решение проблемы доступности.

> [все примеры кода можно найти в](https://github.com/newbe36524/Newbe.Demo).Если Github Clone имеет проблемы,[вы также можете нажать здесь, чтобы сделать Clone](https://gitee.com/yks/Newbe.Demo)

## Часто задаваемые вопросы

Ответы на некоторые распространенные вопросы здесь.

### Является ли клиент результатом ожидания массовой операции?

Это вопрос, поднятый многими netizens.Ответ :：Да.

Предположим, мы обнародовали WebApi в качестве интерфейса, вызываемого браузером.Если одновременно 100 браузеров одновременно запрашивают.

Затем эти 100 запросов объединяются и записываются в базу данных.Ни один из этих клиентов не получит ответа от службы и будет ждать до тех пор, пока они не будут записаны в базу данных.

Это также место, где схема слияния отличается от обычной схемы "написать очередь, а затем написать библиотеку".

### По принципу, что это не то же самое, что bulkcopy?

Они не связаны между ними и должны быть функциональными одновременно. Во-первых, database в коде. InsertMany - это bulkcopy, о котором вы упомянули.

Ключом к этому коду является не InsertMany, а то, как объединить один запрос на вставку. Представьте себе, что вы можете открыть API bulkcopy на webapi. Однако нельзя объединить запросы от разных клиентов в один API для вызова bulkcopy. Например, 10 000 клиентов вызывают ваш API, так как же объединить эти запросы API?

Если таким образом, хотя вы просто предоставляете API с одной вставкой для внешнего мира.Вы реализуете слияние из разных клиентских запросов и становитесь доступными для bulkcopy.Это имеет смысл при высоких и многое из того, что находится в то же время.

Кроме того, это согласуется с принципом открытия и закрытия, так как вы не изменили интерфейс InsertOne Repository, но реализовали эффект bulkcopy.

### Если одно исключение операции в пакетной операции завершается неудачей, приведет ли все другие операции, которые были объединены, к сбою?

Если бизнес-сценарий заключается в том, что слияние будет иметь влияние, это, конечно, не должно быть объединено.

Пакетная операция завершается неудачей, конечно, вместе, так как базовая транзакция базы данных, безусловно, не удается вместе.

Если пакетный интерфейс также не поддерживает дифференцированное обращение с каждым входящим идентификатором.Типичные, такие как mongodb bulkcopy может вернуть, какие успехи и какие неудачи, то у нас есть возможность установить различные состояния TCS.

Какие слияния, а какие нет, полностью зависят от бизнеса.Примером является то, как слияние должно быть, если вы хотите объединить его.Не требуется, чтобы все было объединено.

### И Инсерт, и Upsert сказали, а как же Delete и Select?

Автор в общих количествах называет этот режим "реактивной пакетной обработкой".Чтобы убедиться, что шаблон применяется в бизнес-сценарии, необходимо выполнить следующие два основных требования：

- Будет ли пакетная обработка ниже по течению бизнеса быстрее, чем кумулятивная обработка одной полосы, и если да, то будет ли она работать
- Будут ли запросы на короткие всплески частоты в восходящем бизнесе, если да, то могут быть использованы

Конечно, необходимо также рассмотреть такие вопросы, как：вниз по течению пакетные операции могут быть разделены на результаты каждого запроса и т.д.Но эти два момента должны быть обсужды.

Итак, возьмем Delete в качестве примера：

- Будет ли Delete Where In быстрее, чем Delete = ?Попробуй
- Будет ли всплеск спроса на Delete?Подумайте об этом

## Гаджет Zeal

Автор является человеком, который не может написать полную хранимую процедуру.Доступ к документам в этих базах данных зависит от оранжевого документа под названием Zeal для просмотра бесплатного программного обеспечения.Рекомендуется для вас, и вы заслуживаете его.

![Zeal](/images/20200627-010.png)

Официальный адрес Zeal：<https://zealdocs.org/>

<!-- md Footer-Newbe-Claptrap.md -->
